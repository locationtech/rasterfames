<!DOCTYPE html>
<html lang="en" class="no-js">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta http-equiv="x-ua-compatible" content="ie=edge">
<meta name="description" content="RasterFrames brings the power of Spark DataFrames to geospatial raster data.">
<meta name="generator" content="Paradox, paradox-material-theme=0.6.0, mkdocs-material=3.0.3">

<meta name="lang:clipboard.copy" content="Copy to clipboard">
<meta name="lang:clipboard.copied" content="Copied to clipboard">
<meta name="lang:search.language" content="">
<meta name="lang:search.pipeline.stopwords" content="true">
<meta name="lang:search.pipeline.trimmer" content="true">
<meta name="lang:search.result.none" content="No matching documents">
<meta name="lang:search.result.one" content="1 matching document">
<meta name="lang:search.result.other" content="# matching documents">
<meta name="lang:search.tokenizer" content="[\s\-]+">


<meta name="description" content="RasterFrames brings the power of Spark DataFrames to geospatial raster data.">
<link rel="shortcut icon" href="assets/images/RasterFrames_32x32.ico">
<title>NumPy and Pandas Â· RasterFrames</title>
<link rel="stylesheet" href="assets/stylesheets/application.451f80e5.css">
<link rel="stylesheet" href="assets/stylesheets/application-palette.22915126.css">
<meta name="theme-color" content="#546e7a" />
<link rel="stylesheet" href="lib/material__tabs/dist/mdc.tabs.min.css">
<link rel="stylesheet" href="lib/prettify/prettify.css">
<script src="assets/javascripts/modernizr.1aa3b519.js"></script>
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700|Roboto+Mono">
<style>
body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}
code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}
</style>
<link rel="stylesheet" href="assets/fonts/font-awesome.css">
<link rel="stylesheet" href="assets/fonts/material-icons.css">
<link rel="stylesheet" href="assets/stylesheets/paradox-material-theme.css">
<link rel="stylesheet" href="assets/custom.css">
</head>
<body
data-md-color-primary="blue-grey"
data-md-color-accent="light-blue"
>
<input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
<input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
<label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
<header class="md-header" data-md-component="header">
<nav class="md-header-nav md-grid">
<div class="md-flex">
<div class="md-flex__cell md-flex__cell--shrink">
<a href="index.html" title="RasterFrames" class="md-header-nav__button md-logo">
<img src="assets/images/RF-R.svg" width="24" height="24">
</a>
</div>
<div class="md-flex__cell md-flex__cell--shrink">
<label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
</div>
<div class="md-flex__cell md-flex__cell--stretch">
<div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
<span class="md-header-nav__topic">
RasterFrames
</span>
<span class="md-header-nav__topic">
NumPy and Pandas
</span>
</div>
</div>
<div class="md-flex__cell md-flex__cell--shrink">
<label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
<div class="md-search" data-md-component="search" role="dialog">
<label class="md-search__overlay" for="__search"></label>
<div class="md-search__inner" role="search">
<form class="md-search__form" name="search">
<input type="text" class="md-search__input" name="query" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query" data-md-state="active">
<label class="md-icon md-search__icon" for="__search"></label>
<button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">&#xE5CD;</button>
</form>
<div class="md-search__output">
<div class="md-search__scrollwrap" data-md-scrollfix>
<div class="md-search-result" data-md-component="result">
<div class="md-search-result__meta">
Type to start searching
</div>
<ol class="md-search-result__list"></ol>
</div>
</div>
</div>
</div>
</div>

</div>
<div class="md-flex__cell md-flex__cell--shrink">
<div class="md-header-nav__source">
<a href="https://github.com/locationtech/rasterframes"
title="Go to repository"
class="md-source"
data-md-source="github">
<div class="md-source__icon">
<i class="fa fa-github"></i>
</div>
<div class="md-source__repository">
locationtech/rasterframes
</div>
</a>

</div>
</div>
</div>
</nav>
</header>

<div class="md-container">
<main class="md-main">
<div class="md-main__inner md-grid" data-md-component="container">
<div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav class="md-nav md-nav--primary" data-md-level="0" style="visibility: hidden">
<label class="md-nav__title md-nav__title--site" for="drawer">
<a href="index.html" title="RasterFrames" class="md-nav__button md-logo">
<span class="md-nav__button md-logo">
<img src="assets/images/RF-R.svg" width="24" height="24">
</a>
<a href="index.html" title="RasterFrames">
RasterFrames
</a>
</label>
<div class="md-nav__source">
<a href="https://github.com/locationtech/rasterframes"
title="Go to repository"
class="md-source"
data-md-source="github">
<div class="md-source__icon">
<i class="fa fa-github"></i>
</div>
<div class="md-source__repository">
locationtech/rasterframes
</div>
</a>

</div>
<ul>
  <li><a href="description.html" class="page">Overview</a></li>
  <li><a href="getting-started.html" class="page">Getting Started</a></li>
  <li><a href="concepts.html" class="page">Concepts</a></li>
  <li><a href="raster-io.html" class="page">Raster Data I/O</a>
  <ul>
    <li><a href="raster-catalogs.html" class="page">Raster Catalogs</a></li>
    <li><a href="raster-read.html" class="page">Reading Raster Data</a></li>
    <li><a href="raster-write.html" class="page">Writing Raster Data</a></li>
  </ul></li>
  <li><a href="vector-data.html" class="page">Vector Data</a></li>
  <li><a href="raster-processing.html" class="page">Raster Processing</a>
  <ul>
    <li><a href="local-algebra.html" class="page">Local Map Algebra</a></li>
    <li><a href="nodata-handling.html" class="page">&ldquo;NoData&rdquo; Handling</a></li>
    <li><a href="masking.html" class="page">Masking</a></li>
    <li><a href="zonal-algebra.html" class="page">Zonal Map Algebra</a></li>
    <li><a href="aggregation.html" class="page">Aggregation</a></li>
    <li><a href="time-series.html" class="page">Time Series</a></li>
    <li><a href="raster-join.html" class="page">Raster Join</a></li>
  </ul></li>
  <li><a href="machine-learning.html" class="page">Machine Learning</a>
  <ul>
    <li><a href="unsupervised-learning.html" class="page">Unsupervised Machine Learning</a></li>
    <li><a href="supervised-learning.html" class="page">Supervised Machine Learning</a></li>
  </ul></li>
  <li><a href="numpy-pandas.html" class="active page">NumPy and Pandas</a></li>
  <li><a href="ipython.html" class="page">IPython/Jupyter Extensions</a></li>
  <li><a href="languages.html" class="page">Scala and SQL</a></li>
  <li><a href="reference.html" class="page">Function Reference</a></li>
  <li><a href="release-notes.html" class="page">Release Notes</a></li>
</ul>
<nav class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">Table of contents</label>
<ul>
  <li><a href="numpy-pandas.html#numpy-and-pandas" class="header">NumPy and Pandas</a>
  <ul>
    <li><a href="numpy-pandas.html#performance-considerations" class="header">Performance Considerations</a></li>
    <li><a href="numpy-pandas.html#the-tile-class" class="header">The <code>Tile</code> Class</a></li>
    <li><a href="numpy-pandas.html#dataframe-topandas" class="header">DataFrame <code>toPandas</code></a></li>
    <li><a href="numpy-pandas.html#user-defined-functions" class="header">User Defined Functions</a></li>
    <li><a href="numpy-pandas.html#creating-a-spark-dataframe" class="header">Creating a Spark DataFrame</a></li>
  </ul></li>
</ul>
</nav>

</nav>
<ul style="display: none">
<li class="md-nav__item md-version" id="project.version">
<label class="md-nav__link" for="__version">
<i class="md-icon" title="Version">label_outline</i> 0.9.1
</label>
</li>
</ul>
</div>
</div>
</div>
<div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">Table of contents</label>
<ul>
  <li><a href="numpy-pandas.html#numpy-and-pandas" class="header">NumPy and Pandas</a>
  <ul>
    <li><a href="numpy-pandas.html#performance-considerations" class="header">Performance Considerations</a></li>
    <li><a href="numpy-pandas.html#the-tile-class" class="header">The <code>Tile</code> Class</a></li>
    <li><a href="numpy-pandas.html#dataframe-topandas" class="header">DataFrame <code>toPandas</code></a></li>
    <li><a href="numpy-pandas.html#user-defined-functions" class="header">User Defined Functions</a></li>
    <li><a href="numpy-pandas.html#creating-a-spark-dataframe" class="header">Creating a Spark DataFrame</a></li>
  </ul></li>
</ul>
</nav>

</div>
</div>
</div>
<div class="md-content">
<article class="md-content__inner md-typeset">
<div class="md-content__searchable">
<h1><a href="#numpy-and-pandas" name="numpy-and-pandas" class="anchor"><span class="anchor-link"></span></a>NumPy and Pandas</h1>
<p>In the Python Spark API, the work of distributed computing over the DataFrame is done on many executors (the Spark term for workers) inside Java virtual machines (JVM). Most calls to <code>pyspark</code> are passed to a Java process via the <code>py4j</code> library. The user can also ask for data inside the JVM to be brought over to the Python driver (the Spark term for the client application). When dealing with <em>tiles</em>, the driver will receive this data as a lightweight wrapper object around a NumPy ndarray. It is also possible to write lambda functions against NumPy arrays and evaluate them in the Spark DataFrame.</p>
<h2><a href="#performance-considerations" name="performance-considerations" class="anchor"><span class="anchor-link"></span></a>Performance Considerations</h2>
<p>When working with large, distributed datasets in Spark, attention is required when invoking <em>actions</em> on the data. In general, <em>transformations</em> are lazily evaluated in Spark, meaning the code runs fast and it doesn&rsquo;t move any data around. But <em>actions</em> cause the evaluation to happen, meaning all the lazily planned <em>transformations</em> are going to be computed and data is going to be processed and moved around. In general, if a <a href="https://spark.apache.org/docs/2.3.2/api/python/pyspark.sql.html"><code>pyspark</code> function</a> returns a DataFrame, it is probably a <em>transformation</em>, and if not, it is an <em>action</em>.</p>
<p>When many <em>actions</em> are invoked, a lot of data can flow from executors to the driver. In <code>pyspark</code>, the data then has to move from the driver JVM to the Python process running the driver. When that happens, if there are any <em>tiles</em> in the data, they will be converted to a Python <a href="https://github.com/locationtech/rasterframes/blob/develop/pyrasterframes/src/main/python/pyrasterframes/rf_types.py"><code>Tile</code></a> object. In practical work with Earth observation data, the <em>tiles</em> are frequently 256 by 256 arrays, which may be 100kb or more each. Individually they are small, but a DataFrame can easily have dozens of such <em>tile</em> columns and millions of rows.</p>
<p>All of this discussion reinforces two important principles for working with Spark: understanding the cost of an <em>action</em> and using <a href="aggregation.html">aggreates</a>, summaries, or samples to manage the cost of <em>actions</em>.</p>
<h2><a href="#the-tile-class" name="the-tile-class" class="anchor"><span class="anchor-link"></span></a>The <code>Tile</code> Class</h2>
<p>In Python, <em>tiles</em> are represented with the <code>rf_types.Tile</code> class. This is a NumPy <code>ndarray</code> with two dimensions, along with some additional metadata allowing correct conversion to the GeoTrellis <a href="nodata-handling.html#cell-types">cell type</a>.</p>
<pre class="prettyprint"><code class="language-python">from pyrasterframes.rf_types import Tile
import numpy as np

t = Tile(np.random.randn(4, 4))
print(str(t))
</code></pre>
<pre><code>Tile(dimensions=[4, 4], cell_type=CellType(float64, nan), cells=
[[-1.6976645785431788 1.438251238090458 0.4955673143482285
  0.07987907645882293]
 [1.0223194602865753 0.12571050448043788 1.407536778526134
  0.4216599411257001]
 [0.2354512884489902 0.8334623245039772 -0.19812995197824723
  0.42326157852859847]
 [0.18779749791929626 0.0837735225844472 -0.34216861550958694
  0.8240808442602573]])
</code></pre>
<p>You can access the NumPy array with the <code>cells</code> member of <code>Tile</code>.</p>
<pre class="prettyprint"><code class="language-python">t.cells.shape, t.cells.nbytes
</code></pre>
<pre><code>((4, 4), 128)
</code></pre>
<h2><a href="#dataframe-topandas" name="dataframe-topandas" class="anchor"><span class="anchor-link"></span></a>DataFrame <code>toPandas</code></h2>
<p>As discussed in the <a href="raster-write.html#dataframe-samples">raster writing chapter</a>, a pretty display of Pandas DataFrame containing <em>tiles</em> is available by importing the <code>rf_ipython</code> submodule. In addition, as discussed in the <a href="vector-data.html">vector data chapter</a>, any geometry type in the Spark DataFrame will be converted into a Shapely geometry. Taken together, we can easily get the spatial information and raster data as a NumPy array, all within a Pandas DataFrame.</p>
<pre class="prettyprint"><code class="language-python">import pyrasterframes.rf_ipython
from pyspark.sql.functions import lit, col

cat = spark.read.format(&#39;aws-pds-modis-catalog&#39;).load() \
        .filter(
            (col(&#39;granule_id&#39;) == &#39;h11v04&#39;) &amp;
            (col(&#39;acquisition_date&#39;) &gt; lit(&#39;2018-02-19&#39;)) &amp;
            (col(&#39;acquisition_date&#39;) &lt; lit(&#39;2018-02-22&#39;))
        )

spark_df = spark.read.raster(cat, catalog_col_names=[&#39;B01&#39;]) \
                .select(
                    &#39;acquisition_date&#39;,
                    &#39;granule_id&#39;,
                    rf_tile(&#39;B01&#39;).alias(&#39;tile&#39;),
                    rf_geometry(&#39;B01&#39;).alias(&#39;tile_geom&#39;)
                    )

pandas_df = spark_df.limit(10).toPandas()
pandas_df.iloc[0].apply(lambda v: type(v))
</code></pre>
<pre><code>acquisition_date    &lt;class &#39;pandas._libs.tslibs.timestamps.Timesta...
granule_id                                              &lt;class &#39;str&#39;&gt;
tile                           &lt;class &#39;pyrasterframes.rf_types.Tile&#39;&gt;
tile_geom                  &lt;class &#39;shapely.geometry.polygon.Polygon&#39;&gt;
Name: 0, dtype: object
</code></pre>
<h2><a href="#user-defined-functions" name="user-defined-functions" class="anchor"><span class="anchor-link"></span></a>User Defined Functions</h2>
<p>As we demonstrated with <a href="vector-data.html#shapely-geometry-support">vector data</a>, we can also make use of the <code>Tile</code> type to create <a href="https://spark.apache.org/docs/2.3.2/api/python/pyspark.sql.html#pyspark.sql.functions.udf">user-defined functions (UDF)</a> that can take a <em>tile</em> as input, return a <em>tile</em> as output, or both. Here is a trivial and <strong>inefficient</strong> example of doing both. A serious performance implication of user defined functions in Python is that all the executors must move the Java objects to Python, evaluate the function, and then move the Python objects back to Java. Use the many <a href="reference.html">built-in functions</a> wherever possible, and ask the <a href="https://gitter.im/locationtech/rasterframes">community</a> if you have an idea for a function that should be included.</p>
<p>We will demonstrate an example of creating a UDF that is logically equivalent to a built-in function. We&rsquo;ll quickly show that the resulting <em>tiles</em> are approximately equivalent. The reason they are not exactly the same is that one is computed in Python and the other is computed in Java.</p>
<pre class="prettyprint"><code class="language-python">from pyrasterframes.rf_types import TileUDT
from pyspark.sql.functions import udf

@udf(TileUDT())
def my_udf(t):
    import numpy as np
    return Tile(np.log1p(t.cells))

udf_df = spark_df.limit(1).select(
            my_udf(&#39;tile&#39;).alias(&#39;udf_result&#39;),
            rf_log1p(&#39;tile&#39;).alias(&#39;built_in_result&#39;)
        ).toPandas()

row = udf_df.iloc[0]
diff = row[&#39;udf_result&#39;] - row[&#39;built_in_result&#39;]
print(type(diff))
np.abs(diff.cells).max()
</code></pre>
<pre><code>&lt;class &#39;pyrasterframes.rf_types.Tile&#39;&gt;
</code></pre>
<pre><code>4.767482870704498e-07
</code></pre>
<p>We can also inspect an image of the difference between the two <em>tiles</em>, which is just random noise. Both <em>tiles</em> have the same structure of NoData, as exhibited by the white areas.</p>
<pre class="prettyprint"><code class="language-python">diff.show(0, 100)
</code></pre>
<pre><code>&lt;AxesSubplot:&gt;
</code></pre>
<p><img src="figures/numpy-pandas_udf_diff_noise_tile_1.png" /></p>
<h2><a href="#creating-a-spark-dataframe" name="creating-a-spark-dataframe" class="anchor"><span class="anchor-link"></span></a>Creating a Spark DataFrame</h2>
<p>You can also create a Spark DataFrame with a column full of <code>Tile</code> objects or Shapely geomtery objects.</p>
<p>The example below will create a Pandas DataFrame with ten rows of noise <em>tiles</em> and random <code>Point</code>s. We will then create a Spark DataFrame from it.</p>
<pre class="prettyprint"><code class="language-python">import pandas as pd
from shapely.geometry import Point

pandas_df = pd.DataFrame([{
    &#39;tile&#39;: Tile(np.random.randn(100, 100)),
    &#39;geom&#39;: Point(-90 + 90 * np.random.random((2, 1)))
    } for _ in range(10)
])

spark_df = spark.createDataFrame(pandas_df)

spark_df.printSchema()
spark_df.count()
</code></pre>
<pre><code>root
 |-- tile: tile (nullable = true)
 |-- geom: point (nullable = true)
</code></pre>
<pre><code>10
</code></pre>
</div>
<div>
<a href="https://github.com/locationtech/rasterframes/tree/v0.9.1/pyrasterframes/target/python/docs/numpy-pandas.md" title="Edit this page" class="md-source-file md-edit">
Edit this page
</a>
</div>
<div class="print-only">
<span class="md-source-file md-version">
0.9.1
</span>
</div>
</article>
</div>
</div>
</main>
<footer class="md-footer">
<div class="md-footer-nav">
<nav class="md-footer-nav__inner md-grid">
<a href="supervised-learning.html" title="Supervised Machine Learning" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
<div class="md-flex__cell md-flex__cell--shrink">
<i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
</div>
<div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
<span class="md-flex__ellipsis">
<span class="md-footer-nav__direction">
Previous
</span>
Supervised Machine Learning
</span>
</div>
</a>
<a href="ipython.html" title="IPython/Jupyter Extensions" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
<div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
<span class="md-flex__ellipsis">
<span class="md-footer-nav__direction">
Next
</span>
IPython/Jupyter Extensions
</span>
</div>
<div class="md-flex__cell md-flex__cell--shrink">
<i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
</div>
</a>
</nav>
</div>
<div class="md-footer-meta md-typeset">
<div class="md-footer-meta__inner md-grid">
<div class="md-footer-copyright">
<div class="md-footer-copyright__highlight">
&copy; 2017-2019 <a href="https://astraea.earth">Astraea</a>, Inc. All rights reserved.
</div>
</div>
</div>
</div>
</footer>

</div>
<script src="assets/javascripts/application.583bbe55.js"></script>
<script src="assets/javascripts/paradox-material-theme.js"></script>
<script>app.initialize({version:"0.17",url:{base:"."}})</script>
<script type="text/javascript" src="lib/prettify/prettify.js"></script>
<script type="text/javascript" src="lib/prettify/lang-scala.js"></script>
<script type="text/javascript">
document.addEventListener("DOMContentLoaded", function(event) {
window.prettyPrint && prettyPrint();
});
</script>
<script>!function(e,a,t,n,o,c,i){e.GoogleAnalyticsObject=o,e.ga=e.ga||function(){(e.ga.q=e.ga.q||[]).push(arguments)},e.ga.l=1*new Date,c=a.createElement(t),i=a.getElementsByTagName(t)[0],c.async=1,c.src="https://www.google-analytics.com/analytics.js",i.parentNode.insertBefore(c,i)}(window,document,"script",0,"ga"),ga("create","UA-106630615-1"),ga("set","anonymizeIp",!0),ga("send","pageview");var links=document.getElementsByTagName("a");Array.prototype.map.call(links,function(e){e.host!=document.location.host&&e.addEventListener("click",function(){var a=e.getAttribute("data-md-action")||"follow";ga("send","event","outbound",a,e.href)})});if(document.forms.search){var query=document.forms.search.query;query.addEventListener("blur",function(){if(this.value){var e=document.location.pathname;ga("send","pageview",e+"?q="+this.value)}})}</script>

</body>
</html>
